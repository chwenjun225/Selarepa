# 1. Visual Encoder

- Nhiá»‡m vá»¥: Chuyá»ƒn Ä‘á»•i áº£nh RGB thÃ´ thÃ nh má»™t chuá»—i "Visual tokens" cÃ³ thá»ƒ xá»­ lÃ½ bá»Ÿi pháº§n ngÃ´n ngá»¯

- CÃ¡ch lÃ m: Sá»­ dá»¥ng SigLIP SoViT-400m/14 - má»™t biáº¿n thá»ƒ Vision Transformers nháº¹ Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c Ä‘á»ƒ trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng hÃ¬nh áº£nh.

- Ká»¹ thuáº­t: "Adaptive visual encoding" nghÄ©a lÃ  encoder cÃ³ thá»ƒ tá»± Ä‘á»™ng Ä‘iá»u chá»‰nh tá»· lá»‡ down-sampling hoáº·c cÃ¡ch cáº¯t patch Ä‘á»ƒ giá»¯ láº¡i thÃ´ng tin cáº§n thiáº¿t, Ä‘áº·c biá»‡t vá»›i áº£nh Ä‘á»™ phÃ¢n giáº£i cao. 


# 2. Compression Layer 

- Nhiá»‡m vá»¥: Giáº£m sá»‘ lÆ°á»£ng visual tokens xuá»‘ng má»©c vá»«a pháº£i Ä‘á»ƒ LLM khÃ´ng pháº£i xá»­ lÃ½ má»™t lÆ°á»£ng quÃ¡ lá»›n dá»¯ liá»‡u (vá»«a tiáº¿t kiá»‡m tÃ­nh toÃ¡n, vá»«a giá»¯ Ä‘Æ°á»£c thÃ´ng tin quan trá»ng).

- CÃ¡ch lÃ m: DÃ¹ng perceiver Resampler - má»™t cáº¥u trÃºc mÃ  á»Ÿ Ä‘Ã¢y chá»‰ dÃ¹ng má»™t layer cross-attention:

(1) Cross-attention: láº¥y má»™t táº­p query (cÃ³ kÃ­ch thÆ°á»›c cá»‘ Ä‘á»‹nh, vÃ­ dá»¥ 64 token) attend lÃªn toÃ n bá»™ visual tokens (key/value) Ä‘á»ƒ "tÃ³m gá»n" chÃºng. 

(2) Káº¿t quáº£ lÃ  má»™t táº­p compressed tokens cÃ³ kÃ­ch thÆ°á»›c nhá» hÆ¡n, nhÆ°ng váº«n há»™i tá»¥ Ä‘á»§ thÃ´ng tin Ä‘áº¡i diá»‡n cho cáº£ áº£nh. 


# 3. Large Language Model 

- Nhiá»‡m vá»¥: Sinh vÄƒn báº£n Ä‘iá»u kiá»‡n dá»±a trÃªn cáº£ compressed visual tokens vÃ  Ä‘áº§u vÃ o vÄƒn báº£n (prompt)

- CÃ¡ch lÃ m: GhÃ©p chuá»—i token cá»§a áº£nh (sau compression) vÃ o trÆ°á»›c hoáº·c sau token cá»§a prompt text, rá»“i cháº¡y quÃ¡ kiáº¿n trÃºc Transformer cá»§a LLM Ä‘á»ƒ sinh tiáº¿p pháº§n text tráº£ lá»i. 


# ğŸ‘‰ TÃ³m láº¡i luá»“ng dá»¯ liá»‡u

Input Image  â”€â”€â–º Visual Encoder (SigLIP SoViT) â”€â”€â–º visual tokens
                                 â”‚
                                 â–¼
                    Compression Layer (Perceiver Resampler)
                                 â”‚
                                 â–¼
           [compressed visual tokens] + [prompt text tokens]
                                 â”‚
                                 â–¼
                     Large Language Model â”€â”€â–º Generated Text


- Má»—i thÃ nh pháº§n lÃ m má»™t viá»‡c chuyÃªn biá»‡t:

1. NhÃ¬n (Visual Encoder)

2. TÃ³m gá»n (Compression Layer)

3. NÃ³i (LLM)

> Kiáº¿n trÃºc nÃ y cho phÃ©p MiniCPM-V vá»«a máº¡nh vá» thá»‹ giÃ¡c (nhá» SoViT), vá»«a gá»n nháº¹ Ä‘á»ƒ cháº¡y trÃªn thiáº¿t bá»‹ biÃªn (nhá» compression chá»‰ má»™t layer), Ä‘á»“ng thá»i táº­n dá»¥ng sá»©c máº¡nh sinh vÄƒn báº£n tiÃªn tiáº¿n cá»§a LLM gá»‘c (Llama3).



















