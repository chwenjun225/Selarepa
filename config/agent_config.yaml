llm:
    # HuggingFace (for local models)
    type: "huggingface"
    model: "Llama-3.2-11B-Vision-Instruct.Q4_K_M:latest" # "DeepSeek-R1-Distill-Qwen-14B-Q4_K_M:latest" # "codellama/CodeLlama-34b-Instruct-hf" 
    api_base: "http://localhost:11434/v1"  # Local API endpoint
    api_key: "EMPTY"  # Can be empty for local models
    device: "cuda"  # Options: cuda, cpu
    torch_dtype: "float16"
    temperature: 0.1
    max_output_tokens: 130000
    max_input_tokens: 130000
    top_p: 0.95
    top_k: 40
    repetition_penalty: 1.2
